{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0379dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dosoa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\dosoa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dosoa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dosoa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string, nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from IPython.display import display, Markdown\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b51887f",
   "metadata": {},
   "source": [
    "# Lettura Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519da93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = pd.read_csv('../data/raw_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a71174",
   "metadata": {},
   "source": [
    "# Conversione Testo (text-clening)\n",
    "\n",
    "### Conversione in Stringa della Colonna 'text_'\n",
    "\n",
    "Per prima cosa viene convertita in stringa la feature \"text_\" per ogni entry del Dataset. Questo tipo di operazione è utile ad assicurarsi che i dati nella colonna 'text_' siano trattati come testo. È utile anche perchè i dati potrebbero essere stati importati con tipi misti o non corretti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5e0f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset['text_'] = raw_dataset['text_'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419ca4ec",
   "metadata": {},
   "source": [
    "### Conversione in lowercase della Colonna 'text_'\n",
    "\n",
    "Adesso, appurato che la colonna \"text_\" contiene solo stringhe, si va a effettuare un'operazione di lowercasing, dove ogni lettera contenuta nella colonna \"text_\" viene convertita in minucola. Questo è fondamentale in analisi del testo e machine learning, dove le differenze tra maiuscole e minuscole spesso non sono significative e possono creare rumore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c4dbeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset['text_'] = raw_dataset['text_'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67529ff",
   "metadata": {},
   "source": [
    "# Pulizia del testo\n",
    "\n",
    "**(Da controllare!)** Successivamente viene definita una routine di operazioni utile a migliorare la qualità del testo. Vediamo perché ciascuna di queste operazioni potrebbe essere utile in questo contesto:\n",
    "\n",
    "**Tokenizzazione:** Suddividere il testo in parole o token è essenziale per analizzare la struttura e il contenuto delle recensioni. In analisi del testo, specialmente in contesti come il rilevamento delle recensioni false, è importante esaminare le parole individuali per identificare modelli, uso di linguaggio insolito, o altre caratteristiche che potrebbero indicare una recensione falsa.\n",
    "\n",
    "**Rimozione delle Stop Words:** Le stop words sono generalmente parole comuni che non aggiungono molto significato al testo. Nel contesto del rilevamento di recensioni false, rimuovere queste parole può aiutare a ridurre il rumore nei dati e consentire al modello di concentrarsi su parole più significative che possono essere più indicative di recensioni autentiche o false.\n",
    "\n",
    "**Rimozione dei Numeri:** I numeri spesso non contribuiscono al rilevamento delle recensioni false, a meno che non siano specificamente rilevanti per il contesto. Rimuovendoli, si riduce ulteriormente il rumore nei dati, permettendo al modello di concentrarsi sul testo chiave.\n",
    "\n",
    "**Rimozione della Punteggiatura:** La punteggiatura può introdurre rumore e complicazioni nell'analisi del testo. Rimuovendo i segni di punteggiatura, si semplifica il testo per l'analisi. Tuttavia, in alcuni casi, la punteggiatura (come l'eccessivo uso di punti esclamativi) potrebbe essere un indicatore di recensioni false, quindi questa decisione dovrebbe essere basata sulla specifica natura del dataset e sull'obiettivo dell'analisi.\n",
    "\n",
    "Queste operazioni di pre-elaborazione aiutano a pulire e standardizzare i dati del testo, migliorando la qualità delle informazioni che alimentano il modello di machine learning. Ciò è particolarmente importante nel rilevamento delle recensioni false, dove la precisione e la chiarezza del testo analizzato possono avere un impatto significativo sui risultati del modello.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dc41e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    return ' '.join([word for word in word_tokenize(text) \n",
    "                     if word not in stopwords.words('english') \n",
    "                     and not word.isdigit() \n",
    "                     and word not in string.punctuation])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb73a3d",
   "metadata": {},
   "source": [
    "### Test routine \"text_cleaning\"\n",
    "\n",
    "Adesso stampiamo due volte la colonna \"text_\" delle prime 3 entry del Dataset. La prima volta stampiamo i valori di partenza, mentre la seconda volta andiamo ad applicare la routine \"text_cleaning\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "148e38e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Stringhe senza pulizia testo:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. love this!  well made, sturdy, and very comfortable.  i love it!very pretty"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. love it, a great upgrade from the original.  i've had mine for a couple of years"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. this pillow saved my back. i love the look and feel of this pillow."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Stringhe con pulizia testo:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. love well made sturdy comfortable love pretty"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. love great upgrade original 've mine couple years"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. pillow saved back love look feel pillow"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stampa le prime 3 stringhe senza pulizia\n",
    "display(Markdown('**Stringhe senza pulizia testo:**'))\n",
    "for i in range(3):\n",
    "    string_dirty = raw_dataset['text_'][i]\n",
    "    display(Markdown(f'{i+1}. {string_dirty}'))\n",
    "\n",
    "# Stampa le prime 3 stringhe con pulizia\n",
    "display(Markdown('**Stringhe con pulizia testo:**'))\n",
    "for i in range(3):\n",
    "    string_cleaned = text_cleaning(raw_dataset['text_'][i])\n",
    "    display(Markdown(f'{i+1}. {string_cleaned}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2775443",
   "metadata": {},
   "source": [
    "Testata la corretta esecuzione della routine, verrà adesso applicata a tutte le entry (routine con tempi di esecuzione molto lunghi):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "077a104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset['text_'] = raw_dataset['text_'].apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b9a6b6",
   "metadata": {},
   "source": [
    "## Stemming & Lemmatazing\n",
    "\n",
    "Lo stemming è il processo di riduzione delle parole alle loro radici o forme base, eliminando prefissi, suffissi e inflessioni. Questo approccio migliora l'analisi del sentimento consolidando varie forme di una parola in una singola radice, aumentando così l'accuratezza e l'efficienza. Ad esempio, \"amare\", \"amato\", e \"amando\" vengono ridotti a \"ama-\", aiutando l'algoritmo a riconoscere che tutte esprimono sentimenti positivi. Questo riduce la complessità del testo e facilita l'identificazione corretta del sentimento, senza che varianti simili della stessa parola vengano interpretate come concetti distinti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c97c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "raw_dataset['text_'] = raw_dataset['text_'].apply(lambda x: stem_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf802802",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "raw_dataset[\"text_\"] = raw_dataset[\"text_\"].apply(lambda text: lemmatize_words(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849325d6",
   "metadata": {},
   "source": [
    "Nell'addestramento di un fake review detector basato su machine learning e analisi del sentimento, la lemmatizzazione e lo stemming possono essere molto utili:\n",
    "\n",
    "1. **Riduzione della Variabilità del Testo**: Le recensioni possono variare molto in termini di stile e uso della lingua. La lemmatizzazione e lo stemming riducono questa variabilità convertendo diverse forme di una parola nella loro forma base o radice. Ciò aiuta l'algoritmo a focalizzarsi sul contenuto essenziale delle recensioni piuttosto che su variazioni linguistiche superficiali.\n",
    "\n",
    "2. **Miglioramento dell'Analisi del Sentimento**: Questi processi semplificano il testo, rendendo più efficace l'analisi del sentimento. Per esempio, parole come \"buono\", \"buoni\", \"buona\" possono essere ridotte alla loro radice (\"buon-\" nello stemming) o al lemma (\"buono\" nella lemmatizzazione), facilitando l'identificazione di sentimenti positivi in maniera coerente.\n",
    "\n",
    "3. **Efficienza nell'Elaborazione**: Sia lo stemming che la lemmatizzazione riducono il numero di termini unici nel dataset, diminuendo così il carico computazionale. Questo può velocizzare l'addestramento del modello e migliorare la sua efficienza operativa.\n",
    "\n",
    "4. **Distinguere le Recensioni Autentiche dalle False**: Le recensioni false possono avere caratteristiche linguistiche uniche, come l'uso eccessivo di parole positive o una struttura frasale innaturale. Analizzando il testo semplificato attraverso stemming e lemmatizzazione, l'algoritmo può imparare a riconoscere questi pattern e identificare più efficacemente le recensioni false.\n",
    "\n",
    "In conclusione, lo stemming e la lemmatizzazione aiutano a pulire e standardizzare il testo delle recensioni, fornendo un input più coerente e gestibile per l'algoritmo di machine learning, il che è cruciale per l'efficacia del fake review detector.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46e545b",
   "metadata": {},
   "source": [
    "Sì, l'analisi del sentimento può essere molto utile in un fake review detector per vari motivi:\n",
    "\n",
    "1. **Identificazione di Pattern Anomali**: Le recensioni false spesso presentano eccessi emotivi, come un entusiasmo smisurato o, al contrario, critiche eccessivamente negative. L'analisi del sentimento può aiutare a identificare questi estremi come possibili indicatori di falsità.\n",
    "\n",
    "2. **Coerenza tra Valutazione e Testo**: In alcune recensioni false, può esserci una discrepanza tra il punteggio assegnato (ad esempio, 5 stelle) e il sentimento espresso nel testo. L'analisi del sentimento può rilevare queste incongruenze.\n",
    "\n",
    "3. **Profilo Emotivo delle Recensioni Autentiche**: Imparando il profilo emotivo tipico delle recensioni autentiche, l'algoritmo può utilizzare l'analisi del sentimento per rilevare deviazioni da questo modello, suggerendo potenziali falsità.\n",
    "\n",
    "4. **Rilevazione di Manipolazioni Strategiche**: Le recensioni false possono essere create per manipolare la percezione di un prodotto o servizio. L'analisi del sentimento può aiutare a identificare tentativi di manipolazione emotiva, che è una pratica comune nelle recensioni artificiose.\n",
    "\n",
    "Tuttavia, è importante notare che l'analisi del sentimento da sola non è sufficiente per rilevare recensioni false con precisione. È meglio utilizzarla in combinazione con altre tecniche analitiche e di machine learning per ottenere risultati più accurati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "436424f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset.to_csv('../data/preprocessed_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8306cbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
