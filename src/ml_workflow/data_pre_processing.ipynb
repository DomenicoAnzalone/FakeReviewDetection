{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0379dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading omw-1.4: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string, nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from IPython.display import display, Markdown\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b51887f",
   "metadata": {},
   "source": [
    "# Lettura Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519da93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = pd.read_csv('../data/raw_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a71174",
   "metadata": {},
   "source": [
    "# Conversione Testo (text-clening)\n",
    "\n",
    "### Conversione in Stringa della Colonna 'text_'\n",
    "\n",
    "Per prima cosa viene convertita in stringa la feature \"text_\" per ogni entry del Dataset. Questo tipo di operazione è utile ad assicurarsi che i dati nella colonna 'text_' siano trattati come testo. È utile anche perchè i dati potrebbero essere stati importati con tipi misti o non corretti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5e0f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset['text_'] = raw_dataset['text_'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419ca4ec",
   "metadata": {},
   "source": [
    "### Conversione in lowercase della Colonna 'text_'\n",
    "\n",
    "Adesso, appurato che la colonna \"text_\" contiene solo stringhe, si va a effettuare un'operazione di lowercasing, dove ogni lettera contenuta nella colonna \"text_\" viene convertita in minucola. Questo è fondamentale in analisi del testo e machine learning, dove le differenze tra maiuscole e minuscole spesso non sono significative e possono creare rumore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c4dbeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset['text_'] = raw_dataset['text_'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67529ff",
   "metadata": {},
   "source": [
    "# Pulizia del testo\n",
    "\n",
    "**(Da controllare!)** Successivamente viene definita una routine di operazioni utile a migliorare la qualità del testo. Vediamo perché ciascuna di queste operazioni potrebbe essere utile in questo contesto:\n",
    "\n",
    "**Tokenizzazione:** Suddividere il testo in parole o token è essenziale per analizzare la struttura e il contenuto delle recensioni. In analisi del testo, specialmente in contesti come il rilevamento delle recensioni false, è importante esaminare le parole individuali per identificare modelli, uso di linguaggio insolito, o altre caratteristiche che potrebbero indicare una recensione falsa.\n",
    "\n",
    "**Rimozione delle Stop Words:** Le stop words sono generalmente parole comuni che non aggiungono molto significato al testo. Nel contesto del rilevamento di recensioni false, rimuovere queste parole può aiutare a ridurre il rumore nei dati e consentire al modello di concentrarsi su parole più significative che possono essere più indicative di recensioni autentiche o false.\n",
    "\n",
    "**Rimozione dei Numeri:** I numeri spesso non contribuiscono al rilevamento delle recensioni false, a meno che non siano specificamente rilevanti per il contesto. Rimuovendoli, si riduce ulteriormente il rumore nei dati, permettendo al modello di concentrarsi sul testo chiave.\n",
    "\n",
    "**Rimozione della Punteggiatura:** La punteggiatura può introdurre rumore e complicazioni nell'analisi del testo. Rimuovendo i segni di punteggiatura, si semplifica il testo per l'analisi. Tuttavia, in alcuni casi, la punteggiatura (come l'eccessivo uso di punti esclamativi) potrebbe essere un indicatore di recensioni false, quindi questa decisione dovrebbe essere basata sulla specifica natura del dataset e sull'obiettivo dell'analisi.\n",
    "\n",
    "Queste operazioni di pre-elaborazione aiutano a pulire e standardizzare i dati del testo, migliorando la qualità delle informazioni che alimentano il modello di machine learning. Ciò è particolarmente importante nel rilevamento delle recensioni false, dove la precisione e la chiarezza del testo analizzato possono avere un impatto significativo sui risultati del modello.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dc41e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    return ' '.join([word for word in word_tokenize(text) \n",
    "                     if word not in stopwords.words('english') \n",
    "                     and not word.isdigit() \n",
    "                     and word not in string.punctuation])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb73a3d",
   "metadata": {},
   "source": [
    "### Test routine \"text_cleaning\"\n",
    "\n",
    "Adesso stampiamo due volte la colonna \"text_\" delle prime 3 entry del Dataset. La prima volta stampiamo i valori di partenza, mentre la seconda volta andiamo ad applicare la routine \"text_cleaning\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "148e38e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Stringhe senza pulizia testo:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. love this!  well made, sturdy, and very comfortable.  i love it!very pretty"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. love it, a great upgrade from the original.  i've had mine for a couple of years"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. this pillow saved my back. i love the look and feel of this pillow."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Stringhe con pulizia testo:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. love well made sturdy comfortable love pretty"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. love great upgrade original 've mine couple years"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. pillow saved back love look feel pillow"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stampa le prime 3 stringhe senza pulizia\n",
    "display(Markdown('**Stringhe senza pulizia testo:**'))\n",
    "for i in range(3):\n",
    "    string_dirty = raw_dataset['text_'][i]\n",
    "    display(Markdown(f'{i+1}. {string_dirty}'))\n",
    "\n",
    "# Stampa le prime 3 stringhe con pulizia\n",
    "display(Markdown('**Stringhe con pulizia testo:**'))\n",
    "for i in range(3):\n",
    "    string_cleaned = text_cleaning(raw_dataset['text_'][i])\n",
    "    display(Markdown(f'{i+1}. {string_cleaned}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2775443",
   "metadata": {},
   "source": [
    "Testata la corretta esecuzione della routine, verrà adesso applicata a tutte le entry (routine con tempi molto lunghi):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "077a104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset['text_'] = raw_dataset['text_'].apply(text_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c97c2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
